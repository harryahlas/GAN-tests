{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mnistgan_test.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"NQdpp84SMur4","colab_type":"text"},"source":["https://github.com/eriklindernoren/Keras-GAN/blob/master/dcgan/dcgan.py"]},{"cell_type":"markdown","metadata":{"id":"hwH_eoMa7MVU","colab_type":"text"},"source":["Set up environment\n","\n","Create images folder\n","Install scipy for use with <code>scipy.misc.imsave()</code> piece."]},{"cell_type":"code","metadata":{"id":"UFLf5wG-uSyh","colab_type":"code","colab":{}},"source":["import os\n","os.mkdir(\"images\")\n","\n","!pip install Pillow==5.0.0\n","!pip install scipy==1.0.1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9IQ9H1Mq693q","colab_type":"text"},"source":["Import images and save to array"]},{"cell_type":"code","metadata":{"id":"bZJUoPJtIQgU","colab_type":"code","colab":{}},"source":["from __future__ import print_function, division\n","\n","from keras.datasets import mnist\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","from keras.models import Sequential, Model\n","from keras.optimizers import Adam\n","import scipy.misc\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import sys\n","import os\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cpk9qXTjIjcc","colab_type":"text"},"source":["Move images to pandas"]},{"cell_type":"code","metadata":{"id":"9Wf1DyyJjDhR","colab_type":"code","colab":{}},"source":["df = pd.read_csv(\"sample_data/mnist_test.csv\")\n","images = df.iloc[:,1:].to_numpy()\n","labels = df.iloc[:,0].values.tolist()\n","print(images.shape)\n","#images.head(2)\n","images[1,1:100]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RCnT-sia623L","colab_type":"text"},"source":["Create images and place into images folder"]},{"cell_type":"code","metadata":{"id":"DfRgk8p2tLuC","colab_type":"code","outputId":"bb1e5677-07f9-4b7d-aab4-0dc069115f43","executionInfo":{"status":"ok","timestamp":1568420149120,"user_tz":420,"elapsed":3134,"user":{"displayName":"harry ahlas","photoUrl":"","userId":"11515999622722943475"}},"colab":{"base_uri":"https://localhost:8080/","height":83}},"source":["for i in range(len(images)):\n","  out = str(\"images/mnist_\" + str(i) + \".png\")\n","  scipy.misc.imsave(out, np.array(images[i]).reshape(28,28))        "],"execution_count":2,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: `imsave` is deprecated!\n","`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n","Use ``imageio.imwrite`` instead.\n","  \n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"vDRWg2GOJWty","colab_type":"text"},"source":["Functions to create:\n","\n","*   the discriminator - <code>build_discriminator</code> \n","*   the generator - <code>build_generator</code>\n","*   an image creator/saver - <code>save_imgs</code>\n","\n","\n"," "]},{"cell_type":"code","metadata":{"id":"3GOtCEKZJQT5","colab_type":"code","colab":{}},"source":["# Discriminator\n","def build_discriminator():\n","\n","    model = Sequential()\n","\n","    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n","    model.add(LeakyReLU(alpha=0.2))\n","    model.add(Dropout(0.25))\n","    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n","    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n","    model.add(BatchNormalization(momentum=0.8))\n","    model.add(LeakyReLU(alpha=0.2))\n","    model.add(Dropout(0.25))\n","    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n","    model.add(BatchNormalization(momentum=0.8))\n","    model.add(LeakyReLU(alpha=0.2))\n","    model.add(Dropout(0.25))\n","    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n","    model.add(BatchNormalization(momentum=0.8))\n","    model.add(LeakyReLU(alpha=0.2))\n","    model.add(Dropout(0.25))\n","    model.add(Flatten())\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","    model.summary()\n","\n","    img = Input(shape=img_shape)\n","    validity = model(img)\n","\n","    return Model(img, validity)\n","\n","# Generator\n","def build_generator():\n","\n","    model = Sequential()\n","\n","    model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=latent_dim))\n","    model.add(Reshape((7, 7, 128)))\n","    model.add(UpSampling2D())\n","    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n","    model.add(BatchNormalization(momentum=0.8))\n","    model.add(Activation(\"relu\"))\n","    model.add(UpSampling2D())\n","    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n","    model.add(BatchNormalization(momentum=0.8))\n","    model.add(Activation(\"relu\"))\n","    model.add(Conv2D(channels, kernel_size=3, padding=\"same\"))\n","    model.add(Activation(\"tanh\"))\n","\n","    model.summary()\n","\n","    noise = Input(shape=(latent_dim,))\n","    img = model(noise)\n","\n","    return Model(noise, img)\n","\n","# Image creator/saver\n","def save_imgs(epoch):\n","    r, c = 5, 5\n","    noise = np.random.normal(0, 1, (r * c, latent_dim))\n","    gen_imgs = generator.predict(noise)\n","\n","    # Rescale images 0 - 1\n","    gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","    fig, axs = plt.subplots(r, c)\n","    cnt = 0\n","    for i in range(r):\n","        for j in range(c):\n","            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n","            axs[i,j].axis('off')\n","            cnt += 1\n","    fig.savefig(\"images/mnist_%d.png\" % epoch)\n","    plt.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qXqOCSQVIrkG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"d0c770c2-8ecc-4b5f-b610-986a80378f3a","executionInfo":{"status":"ok","timestamp":1568426424132,"user_tz":420,"elapsed":2125,"user":{"displayName":"harry ahlas","photoUrl":"","userId":"11515999622722943475"}}},"source":["# Input shape\n","img_rows = 28\n","img_cols = 28\n","channels = 1\n","img_shape = (img_rows, img_cols, channels)\n","latent_dim = 100\n","\n","optimizer = Adam(0.0002, 0.5)\n","\n","\n","# Build and compile the discriminator\n","discriminator = build_discriminator()\n","discriminator.compile(loss='binary_crossentropy',\n","    optimizer=optimizer,\n","    metrics=['accuracy'])\n","\n","# Build the generator\n","generator = build_generator()\n","\n","# The generator takes noise as input and generates imgs\n","z = Input(shape=(latent_dim,))\n","img = generator(z)\n","\n","# For the combined model we will only train the generator\n","discriminator.trainable = False\n","\n","# The discriminator takes generated images as input and determines validity\n","valid = discriminator(img)\n","\n","# The combined model  (stacked generator and discriminator)\n","# Trains the generator to fool the discriminator\n","combined = Model(z, valid)\n","combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Model: \"sequential_7\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_19 (Conv2D)           (None, 14, 14, 32)        320       \n","_________________________________________________________________\n","leaky_re_lu_13 (LeakyReLU)   (None, 14, 14, 32)        0         \n","_________________________________________________________________\n","dropout_13 (Dropout)         (None, 14, 14, 32)        0         \n","_________________________________________________________________\n","conv2d_20 (Conv2D)           (None, 7, 7, 64)          18496     \n","_________________________________________________________________\n","zero_padding2d_4 (ZeroPaddin (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","batch_normalization_14 (Batc (None, 8, 8, 64)          256       \n","_________________________________________________________________\n","leaky_re_lu_14 (LeakyReLU)   (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","dropout_14 (Dropout)         (None, 8, 8, 64)          0         \n","_________________________________________________________________\n","conv2d_21 (Conv2D)           (None, 4, 4, 128)         73856     \n","_________________________________________________________________\n","batch_normalization_15 (Batc (None, 4, 4, 128)         512       \n","_________________________________________________________________\n","leaky_re_lu_15 (LeakyReLU)   (None, 4, 4, 128)         0         \n","_________________________________________________________________\n","dropout_15 (Dropout)         (None, 4, 4, 128)         0         \n","_________________________________________________________________\n","conv2d_22 (Conv2D)           (None, 4, 4, 256)         295168    \n","_________________________________________________________________\n","batch_normalization_16 (Batc (None, 4, 4, 256)         1024      \n","_________________________________________________________________\n","leaky_re_lu_16 (LeakyReLU)   (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","dropout_16 (Dropout)         (None, 4, 4, 256)         0         \n","_________________________________________________________________\n","flatten_4 (Flatten)          (None, 4096)              0         \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 1)                 4097      \n","=================================================================\n","Total params: 393,729\n","Trainable params: 392,833\n","Non-trainable params: 896\n","_________________________________________________________________\n","Model: \"sequential_8\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_7 (Dense)              (None, 6272)              633472    \n","_________________________________________________________________\n","reshape_3 (Reshape)          (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","up_sampling2d_5 (UpSampling2 (None, 14, 14, 128)       0         \n","_________________________________________________________________\n","conv2d_23 (Conv2D)           (None, 14, 14, 128)       147584    \n","_________________________________________________________________\n","batch_normalization_17 (Batc (None, 14, 14, 128)       512       \n","_________________________________________________________________\n","activation_7 (Activation)    (None, 14, 14, 128)       0         \n","_________________________________________________________________\n","up_sampling2d_6 (UpSampling2 (None, 28, 28, 128)       0         \n","_________________________________________________________________\n","conv2d_24 (Conv2D)           (None, 28, 28, 64)        73792     \n","_________________________________________________________________\n","batch_normalization_18 (Batc (None, 28, 28, 64)        256       \n","_________________________________________________________________\n","activation_8 (Activation)    (None, 28, 28, 64)        0         \n","_________________________________________________________________\n","conv2d_25 (Conv2D)           (None, 28, 28, 1)         577       \n","_________________________________________________________________\n","activation_9 (Activation)    (None, 28, 28, 1)         0         \n","=================================================================\n","Total params: 856,193\n","Trainable params: 855,809\n","Non-trainable params: 384\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bhFlFPKPcyZQ","colab_type":"code","colab":{}},"source":["# Variables\n","epochs=40 #4000\n","batch_size=32\n","save_interval=50\n","\n","# Load the dataset\n","(X_train, _), (_, _) = mnist.load_data()\n","\n","# Rescale -1 to 1\n","X_train = X_train / 127.5 - 1.\n","X_train = np.expand_dims(X_train, axis=3)\n","\n","# Adversarial ground truths\n","valid = np.ones((batch_size, 1))\n","fake = np.zeros((batch_size, 1))\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H8BRXGKBe_Ln","colab_type":"text"},"source":["Train to generator object"]},{"cell_type":"code","metadata":{"id":"uqXjXbo9e91G","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":420},"outputId":"c848288b-003d-41f9-966c-dacc34174fc8"},"source":["for epoch in range(epochs):\n","  print(epoch)\n","  # ---------------------\n","  #  Train Discriminator\n","  # ---------------------\n","\n","  # Select a random half of images\n","  idx = np.random.randint(0, X_train.shape[0], batch_size)\n","  imgs = X_train[idx]\n","\n","  # Sample noise and generate a batch of new images\n","  noise = np.random.normal(0, 1, (batch_size, latent_dim))\n","  gen_imgs = generator.predict(noise)\n","\n","  # Train the discriminator (real classified as ones and generated as zeros)\n","  d_loss_real = discriminator.train_on_batch(imgs, valid)\n","  d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n","  d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","  # ---------------------\n","  #  Train Generator\n","  # ---------------------\n","\n","  # Train the generator (wants discriminator to mistake images as real)\n","  g_loss = combined.train_on_batch(noise, valid)\n","\n","  # Plot the progress\n","  print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n","\n","  # If at save interval => save generated image samples\n","  if epoch % save_interval == 0:\n","      save_imgs(epoch)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n","/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n"],"name":"stderr"},{"output_type":"stream","text":["0 [D loss: 1.012166, acc.: 40.62%] [G loss: 0.800072]\n","1\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n"],"name":"stderr"},{"output_type":"stream","text":["1 [D loss: 0.586359, acc.: 75.00%] [G loss: 1.081539]\n","2\n","2 [D loss: 0.580172, acc.: 62.50%] [G loss: 1.130434]\n","3\n","3 [D loss: 0.503563, acc.: 71.88%] [G loss: 1.258011]\n","4\n","4 [D loss: 0.480252, acc.: 75.00%] [G loss: 1.240510]\n","5\n","5 [D loss: 0.378949, acc.: 81.25%] [G loss: 1.457744]\n","6\n","6 [D loss: 0.385059, acc.: 79.69%] [G loss: 1.156055]\n","7\n","7 [D loss: 0.323712, acc.: 89.06%] [G loss: 0.954327]\n","8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aLexCeGRMkYH","colab_type":"code","colab":{}},"source":["\n","\n","class DCGAN():\n","    def __init__(self):\n","       \n","\n","\n","\n","\n","    def train(self, epochs, batch_size=128, save_interval=50):\n","\n","       \n","        \n","\n","    \n","\n","\n","if __name__ == '__main__':\n","    dcgan = DCGAN()\n","    dcgan.train(epochs=4000, batch_size=32, save_interval=50)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RBkMJmcvI0Mg","colab_type":"text"},"source":["View images from first 100 epochs"]},{"cell_type":"code","metadata":{"id":"yMW2a6zSI06Y","colab_type":"code","outputId":"88d9576c-1a57-48db-ffd0-33440ea1818f","executionInfo":{"status":"ok","timestamp":1568420110138,"user_tz":420,"elapsed":304,"user":{"displayName":"harry ahlas","photoUrl":"","userId":"11515999622722943475"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["from IPython.display import Image\n","Image('images/mnist_100.png')\n"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"image/png":"images/mnist_100.png","text/plain":["<IPython.core.display.Image object>"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"FleKGDLmI1fZ","colab_type":"text"},"source":["View images from last epoch"]},{"cell_type":"code","metadata":{"id":"tfs6K9m1I2JE","colab_type":"code","outputId":"3f149a46-86fd-4d54-c3c7-da17f8496f96","executionInfo":{"status":"ok","timestamp":1568420113513,"user_tz":420,"elapsed":314,"user":{"displayName":"harry ahlas","photoUrl":"","userId":"11515999622722943475"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["Image('images/mnist_3900.png')"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"image/png":"images/mnist_3900.png","text/plain":["<IPython.core.display.Image object>"]},"metadata":{"tags":[]},"execution_count":4}]}]}